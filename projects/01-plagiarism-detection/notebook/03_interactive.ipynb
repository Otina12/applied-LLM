{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b6484f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247dcf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from openai import OpenAI\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cc41ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "\n",
    "base_dir = Path(\".\")\n",
    "data_dir = base_dir / \"data\"\n",
    "indexes_dir = base_dir / \"indexes\"\n",
    "\n",
    "dense_index_path = indexes_dir / \"dense_index.faiss\"\n",
    "dense_meta_path = indexes_dir / \"dense_meta.json\"\n",
    "bm25_path = indexes_dir / \"bm25_index.pkl\"\n",
    "test_dataset_path = data_dir / \"test_dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c302997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dense index with 371 chunks\n"
     ]
    }
   ],
   "source": [
    "# load dense index and meta\n",
    "\n",
    "if not dense_index_path.exists():\n",
    "    raise FileNotFoundError(f\"FAISS index not found at {dense_index_path}\")\n",
    "\n",
    "dense_index = faiss.read_index(str(dense_index_path))\n",
    "\n",
    "with open(dense_meta_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    dense_meta = json.load(f)\n",
    "\n",
    "chunk_ids = dense_meta[\"chunk_ids\"]\n",
    "chunk_repos = dense_meta[\"repos\"]\n",
    "chunk_paths = dense_meta[\"paths\"]\n",
    "chunk_texts = dense_meta[\"texts\"]\n",
    "\n",
    "print(f\"loaded dense index with {len(chunk_ids)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aea30e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded bm25 index with 371 chunks\n"
     ]
    }
   ],
   "source": [
    "# load bm25\n",
    "\n",
    "with open(bm25_path, \"rb\") as f:\n",
    "    bm25_pack = pickle.load(f)\n",
    "\n",
    "bm25 = bm25_pack[\"bm25\"]\n",
    "bm25_chunks = bm25_pack[\"chunks\"]\n",
    "\n",
    "print(f\"loaded bm25 index with {len(bm25_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0e823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "\n",
    "emb_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "oai_client = None\n",
    "\n",
    "if openai_api_key:\n",
    "    oai_client = OpenAI(api_key=openai_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2610823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "\n",
    "def embed_code(text):\n",
    "    vec = emb_model.encode([text], convert_to_numpy=True)\n",
    "    return vec.astype(\"float32\")\n",
    "\n",
    "def tokenize_code(text):\n",
    "    return re.findall(r\"[A-Za-z_][A-Za-z0-9_]*\", text)\n",
    "\n",
    "def find_text_by_path(path):\n",
    "    for c in bm25_chunks:\n",
    "        if c[\"source_path\"] == path:\n",
    "            return c[\"text\"]\n",
    "    return None\n",
    "\n",
    "class PlagiarismResult(BaseModel): # Pydantic model for structured output from OpenAI\n",
    "    is_plagiarized: bool\n",
    "    reason: str\n",
    "    evidence: List[str] = []\n",
    "\n",
    "def llm_call(prompt) -> PlagiarismResult:\n",
    "    if oai_client is None:\n",
    "        return PlagiarismResult(is_plagiarized = False, reason = \"no OPENAI_API_KEY in env, skipping LLM detection\", evidence = [])\n",
    "    \n",
    "    oai_response = oai_client.chat.completions.parse(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a careful code plagiarism checker.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format = PlagiarismResult,\n",
    "        temperature = 0.0\n",
    "    )\n",
    "\n",
    "    return oai_response.choices[0].message.parsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure embedding search\n",
    "\n",
    "def detect_embedding(code_query, top_k = 10, similarity_threshold = 0.75):\n",
    "    query_vec = embed_code(code_query)\n",
    "    distances, indexes = dense_index.search(query_vec, top_k)\n",
    "    evidence = []\n",
    "\n",
    "    # distance is L2 norm, and it's directly related to cosine similarity: D(a, b) = 2 - 2 * cos(Î˜)\n",
    "    # the less the distance, the more similar two documents are.\n",
    "    # we need to convert this into a formula.\n",
    "    # simplest option is: similarity = 1 / (1 + distance)\n",
    "    # this way:\n",
    "    # when distance is 0, documents are the same, and similarity score will be 1.\n",
    "    # when distance is large, documents are very different, and similarity score will be significantly less than 1.\n",
    "    \n",
    "    for dist, idx in zip(distances[0], indexes[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "\n",
    "        similarity = 1.0 / (1.0 + float(dist))\n",
    "        \n",
    "        evidence.append(\n",
    "            {\n",
    "                \"chunk_id\": chunk_ids[idx],\n",
    "                \"repo\": chunk_repos[idx],\n",
    "                \"path\": chunk_paths[idx],\n",
    "                #\"text\": chunk_texts[idx],\n",
    "                \"similarity\": similarity\n",
    "            }\n",
    "        )\n",
    "\n",
    "    is_plagiarized = any(e[\"similarity\"] >= similarity_threshold for e in evidence)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"pure_embedding\",\n",
    "        \"is_plagiarized\": is_plagiarized,\n",
    "        \"threshold\": similarity_threshold,\n",
    "        \"evidence\": {\n",
    "            \"mine\": evidence,\n",
    "            \"oai\": \"\" # no llm call\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a65e235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct LLM analysis\n",
    "\n",
    "def build_prompt(corpus_snippets, code_query):\n",
    "    code_snippets = \"\\n\".join(\n",
    "        f\"[{i}]\\n```go\\n{snippet}\\n```\" for i, snippet in enumerate(corpus_snippets, 1)\n",
    "    )\n",
    "    return (\n",
    "        \"You are checking code plagiarism.\\n\"\n",
    "        \"You will get a query function and several candidate snippets.\\n\"\n",
    "        \"Answer with the provided response format.\\n\\n\"\n",
    "        f\"Query code:\\n```go\\n{code_query}\\n```\\n\\n\"\n",
    "        f\"Candidate snippets:\\n{code_snippets}\\n\\n\"\n",
    "        \"Think about structure, call order, and control flow, not only names.\"\n",
    "    )\n",
    "\n",
    "def detect_llm(code_query, top_n = 25):\n",
    "    corpus_snippets = [text for text in chunk_texts[:top_n]]\n",
    "    prompt = build_prompt(corpus_snippets, code_query)\n",
    "    result = llm_call(prompt)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"direct_llm\",\n",
    "        \"is_plagiarized\": result.is_plagiarized,\n",
    "        \"reason\": result.reason,\n",
    "        \"evidence\": {\n",
    "            \"mine\": \"\", # no our analysis\n",
    "            \"oai\": result.evidence\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ed1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard RAG\n",
    "\n",
    "def detect_rag(code_query, top_k = 5):\n",
    "    query_vec = embed_code(code_query)\n",
    "    distances, indexes = dense_index.search(query_vec, top_k)\n",
    "\n",
    "    corpus_snippets = []\n",
    "    evidence = []\n",
    "\n",
    "    for dist, idx in zip(distances[0], indexes[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "\n",
    "        path = chunk_paths[idx]\n",
    "        text = chunk_texts[idx]\n",
    "        \n",
    "        corpus_snippets.append(text)\n",
    "        \n",
    "        similarity = 1.0 / (1.0 + float(dist))\n",
    "        \n",
    "        evidence.append({\n",
    "            \"path\": path,\n",
    "            \"text\": text,\n",
    "            \"similarity\": similarity\n",
    "        })\n",
    "\n",
    "    prompt = build_prompt(corpus_snippets, code_query)\n",
    "    result = llm_call(prompt)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"rag\",\n",
    "        \"is_plagiarized\": result.is_plagiarized,\n",
    "        \"reason\": result.reason,\n",
    "        \"evidence\": {\n",
    "            \"mine\": evidence,\n",
    "            \"oai\": result.evidence\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc6013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hybrid RAG\n",
    "\n",
    "def retrieve_dense(code_query, top_k = 5):\n",
    "    vec = embed_code(code_query)\n",
    "    distances, indexes = dense_index.search(vec, top_k)\n",
    "\n",
    "    out = []\n",
    "    for dist, idx in zip(distances[0], indexes[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "\n",
    "        out.append(\n",
    "            {\n",
    "                \"index\": int(idx),\n",
    "                \"dist\": float(dist),\n",
    "                \"path\": chunk_paths[idx],\n",
    "                \"repo\": chunk_repos[idx],\n",
    "                \"text\": chunk_texts[idx]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "def retrieve_bm25(code_query, top_k = 5):\n",
    "    toks = tokenize_code(code_query)\n",
    "    scores = bm25.get_scores(toks)\n",
    "    idxs = np.argsort(scores)[::-1][:top_k]\n",
    "\n",
    "    out = []\n",
    "    for i in idxs:\n",
    "        out.append(\n",
    "            {\n",
    "                \"index\": int(i),\n",
    "                \"score\": float(scores[i]),\n",
    "                \"path\": bm25_chunks[i][\"source_path\"],\n",
    "                \"repo\": bm25_chunks[i][\"repo\"],\n",
    "                \"text\": bm25_chunks[i][\"text\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "def detect_hybrid_rag(code_query, top_k_dense = 5, top_k_bm25 = 5, top_k_fused = 5, w_dense = 0.5):\n",
    "    top_k_fused = min(top_k_fused, top_k_dense + top_k_bm25)\n",
    "    \n",
    "    # retrieve from both methods\n",
    "    dense_hits = retrieve_dense(code_query, top_k = top_k_dense)\n",
    "    bm25_hits = retrieve_bm25(code_query, top_k = top_k_bm25)\n",
    "\n",
    "    # normalize dense scores to 0..1\n",
    "    dense_scores = {}\n",
    "    dists = [h[\"dist\"] for h in dense_hits]\n",
    "    d_max = max(dists)\n",
    "    d_min = min(dists)\n",
    "\n",
    "    for h in dense_hits:\n",
    "        if d_max == d_min:\n",
    "            s = 1.0\n",
    "        else:\n",
    "            s = 1.0 - (h[\"dist\"] - d_min) / (d_max - d_min)\n",
    "        dense_scores[h[\"index\"]] = s\n",
    "\n",
    "    # normalize bm25 scores to 0..1\n",
    "    bm25_scores = {}\n",
    "    b_max = max(h[\"score\"] for h in bm25_hits)\n",
    "\n",
    "    for h in bm25_hits:\n",
    "        s = h[\"score\"] / b_max if b_max > 0 else 0.0\n",
    "        bm25_scores[h[\"index\"]] = s\n",
    "\n",
    "    # fuse based on weight\n",
    "    fused = {}\n",
    "\n",
    "    for idx, s in dense_scores.items():\n",
    "        fused[idx] = fused.get(idx, 0.0) + w_dense * s\n",
    "\n",
    "    for idx, s in bm25_scores.items():\n",
    "        fused[idx] = fused.get(idx, 0.0) + (1.0 - w_dense) * s\n",
    "\n",
    "    # sort fused scores and take top 'top_k_fused'\n",
    "    fused_sorted = sorted(fused.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_indices = [idx for idx, _ in fused_sorted[:top_k_fused]]\n",
    "\n",
    "    corpus_snippets = []\n",
    "    evidence = []\n",
    "\n",
    "    for idx in top_indices:\n",
    "        text = chunk_texts[idx]\n",
    "        path = chunk_paths[idx]\n",
    "        repo = chunk_repos[idx]\n",
    "\n",
    "        corpus_snippets.append(text)\n",
    "\n",
    "        evidence.append(\n",
    "            {\n",
    "                \"index\": int(idx),\n",
    "                \"repo\": repo,\n",
    "                \"path\": path,\n",
    "                \"dense_score\": dense_scores.get(idx),\n",
    "                \"bm25_score\": bm25_scores.get(idx),\n",
    "                \"fused_score\": fused.get(idx)\n",
    "            }\n",
    "        )\n",
    "\n",
    "    prompt = build_prompt(corpus_snippets, code_query)\n",
    "    result = llm_call(prompt)\n",
    "\n",
    "    return {\n",
    "        \"method\": \"hybrid_rag\",\n",
    "        \"is_plagiarized\": result.is_plagiarized,\n",
    "        \"reason\": result.reason,\n",
    "        \"evidence\": {\n",
    "            \"mine\": evidence,\n",
    "            \"oai\": result.evidence\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be246285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'pure_embedding', 'is_plagiarized': False, 'threshold': 0.75, 'results': [{'chunk_id': 'chunk_00245', 'repo': 'proglog', 'path': 'proglog\\\\ClientSideServiceDiscovery\\\\cmd\\\\proglog\\\\main.go', 'similarity': 0.470111525146902}, {'chunk_id': 'chunk_00316', 'repo': 'raft-go', 'path': 'raft-go\\\\raft\\\\config.go', 'similarity': 0.43569022862522483}, {'chunk_id': 'chunk_00167', 'repo': 'leetcode-go', 'path': 'leetcode-go\\\\1092-maximum-difference-between-node-and-ancestor\\\\maximum-difference-between-node-and-ancestor.go', 'similarity': 0.43035147234894644}, {'chunk_id': 'chunk_00107', 'repo': 'interpreter-go', 'path': 'interpreter-go\\\\lexer\\\\lexer_test.go', 'similarity': 0.4250607547575181}, {'chunk_id': 'chunk_00318', 'repo': 'raft-go', 'path': 'raft-go\\\\raft\\\\config.go', 'similarity': 0.4244408177432547}, {'chunk_id': 'chunk_00274', 'repo': 'raft-go', 'path': 'raft-go\\\\mygob\\\\gob.go', 'similarity': 0.4230892547203589}, {'chunk_id': 'chunk_00272', 'repo': 'raft-go', 'path': 'raft-go\\\\mygob\\\\gob.go', 'similarity': 0.42130618151194565}, {'chunk_id': 'chunk_00162', 'repo': 'leetcode-go', 'path': 'leetcode-go\\\\1055-pairs-of-songs-with-total-durations-divisible-by-60\\\\pairs-of-songs-with-total-durations-divisible-by-60.go', 'similarity': 0.4195810295896227}, {'chunk_id': 'chunk_00149', 'repo': 'interpreter-go', 'path': 'interpreter-go\\\\parser\\\\parser_test.go', 'similarity': 0.4189124984781315}, {'chunk_id': 'chunk_00169', 'repo': 'leetcode-go', 'path': 'leetcode-go\\\\1184-car-pooling\\\\car-pooling.go', 'similarity': 0.41742722934047943}]}\n",
      "{'method': 'direct_llm', 'is_plagiarized': False, 'reason': 'The query code is a simple function that adds two integers, while the candidate snippets are part of a larger download management system with complex structures and functionalities. There is no structural or functional similarity between the query and the candidates.', 'evidence': []}\n",
      "{'method': 'rag', 'is_plagiarized': False, 'reason': 'The candidate snippets do not share structural or functional similarities with the query code. They implement different functionalities and do not exhibit any significant resemblance in terms of logic or flow.', 'evidence': {'standard_rag': [{'path': 'proglog\\\\ClientSideServiceDiscovery\\\\cmd\\\\proglog\\\\main.go', 'text': 'func main() {\\n\\t\\n}', 'similarity': 0.470111525146902}, {'path': 'raft-go\\\\raft\\\\config.go', 'text': 'func (cfg *config) rpcTotal() int {\\n\\treturn cfg.net.GetTotalCount()\\n}', 'similarity': 0.43569022862522483}, {'path': 'leetcode-go\\\\1092-maximum-difference-between-node-and-ancestor\\\\maximum-difference-between-node-and-ancestor.go', 'text': 'func abs(num int) int {\\n    if num < 0 {\\n        return -num\\n    }\\n\\n    return num\\n}', 'similarity': 0.43035147234894644}, {'path': 'interpreter-go\\\\lexer\\\\lexer_test.go', 'text': 'func TestNextToken(t *testing.T) {\\n\\tinput := `\\n\\t\\tlet two = 2;\\n\\t\\tlet three = 3;\\n\\n\\t\\tlet add = fn(x, y) {\\n\\t\\t\\tx + y;\\n\\t\\t};\\n\\n\\t\\tlet result = add(two, three);\\n\\n\\t\\t3 == 3\\n\\t\\t4 < 5\\n\\t\\t6 > 700\\n\\t\\t8 != 9\\n\\n\\t\\tlet fiveStr = \"five\";\\n\\t`\\n\\n\\ttests := []tokenStruct{\\n\\t\\t{token.Let, \"let\"},\\n\\t\\t{token.Identifier, \"two\"},\\n\\t\\t{token.Assign, \"=\"},\\n\\t\\t{token.Int, \"2\"},\\n\\t\\t{token.Semicolon, \";\"},\\n\\t\\t{token.Let, \"let\"},\\n\\t\\t{token.Identifier, \"three\"},\\n\\t\\t{token.Assign, \"=\"},\\n\\t\\t{token.Int, \"3\"},\\n\\t\\t{token.Semicolon, \";\"},\\n\\t\\t{token.Let, \"let\"},\\n\\t\\t{token.Identifier, \"add\"},\\n\\t\\t{token.Assign, \"=\"},\\n\\t\\t{token.Function, \"fn\"},\\n\\t\\t{token.LeftParen, \"(\"},\\n\\t\\t{token.Identifier, \"x\"},\\n\\t\\t{token.Comma, \",\"},\\n\\t\\t{token.Identifier, \"y\"},\\n\\t\\t{token.RightParen, \")\"},\\n\\t\\t{token.LeftBrace, \"{\"},\\n\\t\\t{token.Identifier, \"x\"},\\n\\t\\t{token.Plus, \"+\"},\\n\\t\\t{token.Identifier, \"y\"},\\n\\t\\t{token.Semicolon, \";\"},\\n\\t\\t{token.RightBrace, \"}\"},\\n\\t\\t{token.Semicolon, \";\"},\\n\\t\\t{token.Let, \"let\"},\\n\\t\\t{token.Identifier, \"result\"},\\n\\t\\t{token.Assign, \"=\"},\\n\\t\\t{token.Identifier, \"add\"},\\n\\t\\t{token.LeftParen, \"(\"},\\n\\t\\t{token.Identifier, \"two\"},\\n\\t\\t{token.Comma, \",\"},\\n\\t\\t{token.Identifier, \"three\"},\\n\\t\\t{token.RightParen, \")\"},\\n\\t\\t{token.Semicolon, \";\"},\\n\\t\\t{token.Int, \"3\"},\\n\\t\\t{token.Equal, \"==\"},\\n\\t\\t{token.Int, \"3\"},\\n\\t\\t{token.Int, \"4\"},\\n\\t\\t{token.LessThan, \"<\"},\\n\\t\\t{token.Int, \"5\"},\\n\\t\\t{token.Int, \"6\"},\\n\\t\\t{token.GreaterThan, \">\"},\\n\\t\\t{token.Int, \"700\"},\\n\\t\\t{token.Int, \"8\"},\\n\\t\\t{token.NotEqual, \"!=\"},\\n\\t\\t{token.Int, \"9\"},\\n\\t\\t{token.Let, \"let\"},\\n\\t\\t{token.Identifier, \"fiveStr\"},\\n\\t\\t{token.Assign, \"=\"},\\n\\t\\t{token.String, \"five\"},\\n\\t\\t{token.Semicolon, \";\"},\\n\\t\\t{token.EOF, \"\"},\\n\\t}\\n\\n\\tl := New(input)\\n\\n\\tfor i, testTok := range tests {\\n\\t\\ttok := l.NextToken()\\n\\n\\t\\tif tok.Type != testTok.expectedType {\\n\\t\\t\\tt.Fatalf(\"tests[%d] - tokentype wrong. expected=%q, got=%q\",\\n\\t\\t\\t\\ti, testTok.expectedType, tok.Type)\\n\\t\\t}\\n\\t\\tif tok.Literal != testTok.expectedLiteral {\\n\\t\\t\\tt.Fatalf(\"tests[%d] - literal wrong. expected=%q, got=%q\",\\n\\t\\t\\t\\ti, testTok.expectedLiteral, tok.Literal)\\n\\t\\t}\\n\\t}\\n}', 'similarity': 0.4250607547575181}, {'path': 'raft-go\\\\raft\\\\config.go', 'text': 'func (cfg *config) bytesTotal() int64 {\\n\\treturn cfg.net.GetTotalBytes()\\n}', 'similarity': 0.4244408177432547}], 'oai': []}}\n",
      "{'method': 'hybrid_rag', 'is_plagiarized': False, 'reason': 'The candidate snippets do not contain any similar structure, functionality, or control flow to the query code. They serve different purposes and do not share any significant code patterns or logic.', 'evidence': {'hybrid_rag': [{'index': 244, 'repo': 'proglog', 'path': 'proglog\\\\ClientSideServiceDiscovery\\\\cmd\\\\proglog\\\\main.go', 'dense_score': 1.0, 'bm25_score': None, 'fused_score': 0.5}, {'index': 148, 'repo': 'interpreter-go', 'path': 'interpreter-go\\\\parser\\\\parser_test.go', 'dense_score': None, 'bm25_score': 1.0, 'fused_score': 0.5}, {'index': 305, 'repo': 'raft-go', 'path': 'raft-go\\\\raft\\\\config.go', 'dense_score': None, 'bm25_score': 0.738976594016125, 'fused_score': 0.3694882970080625}, {'index': 248, 'repo': 'proglog', 'path': 'proglog\\\\ClientSideServiceDiscovery\\\\internal\\\\agent\\\\agent.go', 'dense_score': None, 'bm25_score': 0.6539530645695303, 'fused_score': 0.32697653228476514}, {'index': 12, 'repo': 'got', 'path': 'got\\\\download.go', 'dense_score': None, 'bm25_score': 0.6514383995226166, 'fused_score': 0.3257191997613083}], 'oai': []}}\n"
     ]
    }
   ],
   "source": [
    "sample_code = \"\"\"package main\n",
    "func add(a int, b int) int {\n",
    "    return a + b\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(detect_embedding(sample_code))\n",
    "print(detect_llm(sample_code))\n",
    "print(detect_rag(sample_code))\n",
    "print(detect_hybrid_rag(sample_code))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
